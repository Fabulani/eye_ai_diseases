{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage.io as io\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage.filters import threshold_mean, sobel\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, List, Union\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.classic_image_utils import *\n",
    "from utils.eye_dataset import *\n",
    "from typing import Callable, Tuple, List\n",
    "from collections import defaultdict, Counter\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn import svm\n",
    "\n",
    "import pywt\n",
    "import scipy\n",
    "\n",
    "base_dir = \"../../data\"\n",
    "image_dir_training = f\"{base_dir}/ODIR-5K/training\"\n",
    "image_dir_testing = f\"{base_dir}/ODIR-5K/testing\"\n",
    "csv_file = f'{base_dir}/ODIR-5K/data.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_diagnostics_from_tensor(labels, diagnostics: torch.Tensor):\n",
    "    first = True\n",
    "    for i in range(0, len(labels)):\n",
    "        if not first:\n",
    "            print(\",\", end=\"\")\n",
    "        if diagnostics[i] == 1:\n",
    "            print(labels[i], end=\"\")\n",
    "    print()\n",
    "    \n",
    "def print_img(title, image):\n",
    "    plt.title(title)\n",
    "    if len(image.shape) >= 3 and min(image.shape) > 1:\n",
    "        plt.imshow(image)\n",
    "    else:\n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM features building for SVM classification\n",
    "\n",
    "We choose to follow the work of (taspinar) presented on this repository aimed to use SVM as an image labeling tool.\n",
    "\n",
    "https://github.com/taspinar/siml/blob/master/notebooks/WV4%20-%20Classification%20of%20ECG%20signals%20using%20the%20Discrete%20Wavelet%20Transform.ipynb\n",
    "\n",
    "It consists on extracting some feature information from the image file by calculating statistics, crossing and entropy from\n",
    "data generated by a wavelet haar transformation.\n",
    "\n",
    "Here we choose also to ignore the cases in which two or more diseases were detected for the same eye (not the same patient).\n",
    "\n",
    "Therefore, if a patient has, for example, glaucoma and cataract on the left eye, this eye will be ignored from this testing. But, if the patient has glaucoma in one eye and cataract on the other, both eyes will be taken into consideration.\n",
    "\n",
    "convert_label() is responsible for converting the Torch tensor having a 8-pos vector, which the 0 pos is Normal, 1 pos is diabetes, 2 pos is glaucoma etc. into the same numeration as presented on Enum TargetLabel (please refer to the Readme and eye_dataset.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_statistics(data):\n",
    "    n5 = np.nanpercentile(data, 5)\n",
    "    n25 = np.nanpercentile(data, 25)\n",
    "    n75 = np.nanpercentile(data, 75)\n",
    "    n95 = np.nanpercentile(data, 95)\n",
    "    median = np.nanpercentile(data, 50)\n",
    "    mean = np.nanmean(data)\n",
    "    std = np.nanstd(data)\n",
    "    var = np.nanvar(data)\n",
    "    rms = np.nanmean(np.sqrt(data**2))\n",
    "\n",
    "    return [n5, n25, n75, n95, median, mean, std, var, rms]\n",
    "\n",
    "def feature_crossings(data):\n",
    "    zero_crossing_indices = np.nonzero(np.diff(np.array(data) > 0))[0]\n",
    "    no_zero_crossings = len(zero_crossing_indices)\n",
    "    mean_crossing_indices = np.nonzero(np.diff(np.array(data) > np.nanmean(data)))[0]\n",
    "    no_mean_crossings = len(mean_crossing_indices)\n",
    "    return [no_zero_crossings, no_mean_crossings]\n",
    "\n",
    "def feature_entropy(data):\n",
    "    counter_values = Counter(data).most_common()\n",
    "    probabilities = [elem[1]/len(data) for elem in counter_values]\n",
    "    entropy=scipy.stats.entropy(probabilities)\n",
    "    return entropy\n",
    "\n",
    "def get_features(data):\n",
    "    entropy = feature_entropy(data)\n",
    "    crossings = feature_crossings(data)\n",
    "    statistics = feature_statistics(data)\n",
    "    return [entropy] + crossings + statistics\n",
    "\n",
    "def convert_label(label: torch.Tensor) -> Tuple[int, bool]:\n",
    "    choosen = None\n",
    "    for i in range(0, len(label)):\n",
    "        if label[i] == 1.0:\n",
    "            if choosen != None:\n",
    "                return [choosen, True]\n",
    "            choosen = i  \n",
    "\n",
    "    return [choosen, False]\n",
    "\n",
    "\n",
    "def build_features(dataset: EyeImageDataset, limit_read: int  = 0):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    if limit_read <= 0:\n",
    "        limit_read = len(dataset)\n",
    "\n",
    "    i = 0\n",
    "    while limit_read > 0:\n",
    "        feature = []\n",
    "        img, label = dataset.__getitem__(i)\n",
    "        i += 1\n",
    "        limit_read -= 1\n",
    "\n",
    "        img = np.array(img).ravel()\n",
    "        label, multilabel = convert_label(label)\n",
    "        if multilabel:\n",
    "            # we'll ignore multilabel classification problems\n",
    "            continue\n",
    "\n",
    "        list_coeff = pywt.wavedec(img, 'haar')\n",
    " \n",
    "        for coeff in list_coeff:\n",
    "            feature += get_features(coeff)\n",
    " \n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "   \n",
    "    f = np.array(features)\n",
    "    l = np.array(labels)\n",
    "\n",
    "    return [f, l]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(features, labels, label_names):\n",
    "    result = {}\n",
    "    for j in label_names:\n",
    "        result[j] = {\n",
    "            'total' : 0,\n",
    "            'correct' : 0\n",
    "        }\n",
    "\n",
    "    for i in range(0, len(features)):    \n",
    "        real_label = label_names[labels[i]]\n",
    "        k = classifier.predict([features[i]])\n",
    "        result[real_label]['total'] += 1\n",
    "        if k == labels[i]:\n",
    "            result[real_label]['correct'] += 1\n",
    "\n",
    "    for j in label_names:\n",
    "        correct = result[j]['correct']\n",
    "        total = result[j]['total']\n",
    "        if total == 0:\n",
    "            print(f'class: {j}, no samples')\n",
    "        else:\n",
    "            print(f'class: {j}, prediction: [{correct} / {total}] {100*correct/total}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Dataset\n",
    "\n",
    "We use the utility class EyeImageDataset() to load the training dataset based on the metadata CSV file and\n",
    "the target image folder\n",
    "\n",
    "The training images will be loaded as needed due to memory constraints.\n",
    "\n",
    "We decide to resize our images to 224x224 and normalize them before we apply de feature extraction.\n",
    "\n",
    "This could be changed as a tool to evaluate this classification model response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "\n",
    "apply_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=input_size),\n",
    "    transforms.CenterCrop(size=input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "ds = EyeImageDataset(root=image_dir_training, data_info_csv_file=csv_file, transform=apply_transforms)\n",
    "\n",
    "classifier = svm.SVC(class_weight='balanced')\n",
    "features, labels = build_features(ds)\n",
    "classifier.fit(features, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results against the training set\n",
    "\n",
    "Here we test our SVM against the training set, to evaluate it's ability to detect eye problems on our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(features=features, labels=labels, label_names=ds.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "\n",
    "apply_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=input_size),\n",
    "    transforms.CenterCrop(size=input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "ds = EyeImageDataset(root=image_dir_testing, data_info_csv_file=csv_file, transform=apply_transforms)\n",
    "\n",
    "classifier = svm.SVC(class_weight='balanced')\n",
    "features, labels = build_features(ds)\n",
    "classifier.fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results against the test set\n",
    "\n",
    "Here we test our SVM against the test set, a different set of images not used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(features=features, labels=labels, label_names=ds.classes)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
