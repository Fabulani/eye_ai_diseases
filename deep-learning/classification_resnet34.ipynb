{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.eye_dataset import *\n",
    "from eye_classifier import *\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading input dataset\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"../../data\"\n",
    "image_dir = f\"{base_dir}/preprocessed_images\"\n",
    "\n",
    "image_dir_training = f\"{base_dir}/ODIR-5K/training\"\n",
    "image_dir_testing = f\"{base_dir}/ODIR-5K/testing\"\n",
    "csv_file = f'{base_dir}/ODIR-5K/data.csv'\n",
    "\n",
    "print ('reading input dataset')\n",
    "input_size = 224\n",
    "\n",
    "apply_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=input_size),\n",
    "    transforms.CenterCrop(size=input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "ds = EyeImageDataset(root=image_dir_training, data_info_csv_file=csv_file, transform=apply_transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResnetEyeClassifier(\n",
      "  (layer 1): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  )\n",
      "  (layer 2): Linear(in_features=1000, out_features=256, bias=True)\n",
      "  (layer 3): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (layer 4): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (layer 5): Linear(in_features=16, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ResnetEyeClassifier(EyeClassifier):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super(ResnetEyeClassifier, self).__init__(model=[\n",
    "\n",
    "            (models.resnet34(pretrained=False), TransferFunction.NotApplicable),\n",
    "\n",
    "            (nn.Linear(in_features=1000, out_features=256),\n",
    "             TransferFunction.LeakyRelu),\n",
    "\n",
    "            (nn.Linear(in_features=256, out_features=64),\n",
    "             TransferFunction.LeakyRelu),\n",
    "\n",
    "            (nn.Linear(in_features=64, out_features=16),\n",
    "             TransferFunction.Relu),\n",
    "\n",
    "            (nn.Linear(in_features=16, out_features=num_classes),\n",
    "             TransferFunction.NotApplicable),\n",
    "        ])\n",
    "\n",
    "\n",
    "nn = ResnetEyeClassifier(num_classes=len(ds.classes))\n",
    "print(nn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (1%) epoch 1/30, loss = 2.1823\n",
      "training (2%) epoch 1/30, loss = 1.4892\n",
      "training (3%) epoch 1/30, loss = 1.4491\n",
      "training (4%) epoch 1/30, loss = 1.3497\n",
      "training (5%) epoch 2/30, loss = 1.2107\n",
      "training (6%) epoch 2/30, loss = 1.6123\n",
      "training (7%) epoch 2/30, loss = 0.9128\n",
      "training (8%) epoch 3/30, loss = 1.2033\n",
      "training (9%) epoch 3/30, loss = 1.3054\n",
      "training (10%) epoch 3/30, loss = 1.4078\n",
      "training (11%) epoch 4/30, loss = 1.5028\n",
      "training (12%) epoch 4/30, loss = 1.2998\n",
      "training (13%) epoch 4/30, loss = 0.9520\n",
      "training (14%) epoch 4/30, loss = 1.4890\n",
      "training (15%) epoch 5/30, loss = 1.4733\n",
      "training (16%) epoch 5/30, loss = 1.3858\n",
      "training (17%) epoch 5/30, loss = 1.5783\n",
      "training (18%) epoch 6/30, loss = 0.9785\n",
      "training (19%) epoch 6/30, loss = 0.8635\n",
      "training (20%) epoch 6/30, loss = 0.9822\n",
      "training (21%) epoch 7/30, loss = 0.8750\n",
      "training (22%) epoch 7/30, loss = 0.7725\n",
      "training (23%) epoch 7/30, loss = 1.1118\n",
      "training (24%) epoch 7/30, loss = 1.2641\n",
      "training (25%) epoch 8/30, loss = 1.2214\n",
      "training (26%) epoch 8/30, loss = 0.8745\n",
      "training (27%) epoch 8/30, loss = 1.2126\n",
      "training (28%) epoch 9/30, loss = 0.6777\n",
      "training (29%) epoch 9/30, loss = 1.0830\n",
      "training (30%) epoch 9/30, loss = 1.3688\n",
      "training (31%) epoch 10/30, loss = 1.3058\n",
      "training (32%) epoch 10/30, loss = 0.9048\n",
      "training (33%) epoch 10/30, loss = 1.3189\n",
      "training (34%) epoch 10/30, loss = 0.8120\n",
      "training (35%) epoch 11/30, loss = 0.9239\n",
      "training (36%) epoch 11/30, loss = 1.0864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_disease_classification_resnet2.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f637269737469616e6f2f446f63756d656e74732f50726f6a656374732f4d6573747261646f2f566973616f436f6d7075746163696f6e616c/workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_disease_classification_resnet2.ipynb#ch0000005vscode-remote?line=1'>2</a>\u001b[0m nn\u001b[39m.\u001b[39mfreeze_layer(\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f637269737469616e6f2f446f63756d656e74732f50726f6a656374732f4d6573747261646f2f566973616f436f6d7075746163696f6e616c/workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_disease_classification_resnet2.ipynb#ch0000005vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m#nn.load_weights('eye_resnet18.dat')\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f637269737469616e6f2f446f63756d656e74732f50726f6a656374732f4d6573747261646f2f566973616f436f6d7075746163696f6e616c/workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_disease_classification_resnet2.ipynb#ch0000005vscode-remote?line=4'>5</a>\u001b[0m \u001b[39m#nn.freeze_layer(0)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f637269737469616e6f2f446f63756d656e74732f50726f6a656374732f4d6573747261646f2f566973616f436f6d7075746163696f6e616c/workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_disease_classification_resnet2.ipynb#ch0000005vscode-remote?line=5'>6</a>\u001b[0m nn\u001b[39m.\u001b[39;49mtrain_model(ds, batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n",
      "File \u001b[0;32m/workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_classifier.py:123\u001b[0m, in \u001b[0;36mEyeClassifier.train_model\u001b[0;34m(self, dataset, num_epochs, batch_size, learning_rate, gpu, verbose, shuffle)\u001b[0m\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_classifier.py?line=119'>120</a>\u001b[0m train_percent_pos \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_classifier.py?line=121'>122</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_classifier.py?line=122'>123</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (images, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_classifier.py?line=124'>125</a>\u001b[0m         device \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__device\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_classifier.py?line=125'>126</a>\u001b[0m         images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=518'>519</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=523'>524</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=524'>525</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=558'>559</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=559'>560</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=560'>561</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=561'>562</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=562'>563</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py:102\u001b[0m, in \u001b[0;36mEyeImageDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=98'>99</a>\u001b[0m img_file, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles[index], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets[index]\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=100'>101</a>\u001b[0m \u001b[39m# img = io.imread(img_file)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=101'>102</a>\u001b[0m img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__read_image__(index)\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=103'>104</a>\u001b[0m \u001b[39m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=104'>105</a>\u001b[0m \u001b[39m# to return a PIL Image\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=105'>106</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img)\n",
      "File \u001b[0;32m/workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py:71\u001b[0m, in \u001b[0;36mEyeImageDataset.__read_image__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=67'>68</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__read_image__\u001b[39m(\u001b[39mself\u001b[39m, index: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=68'>69</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__buffer_max_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=69'>70</a>\u001b[0m         \u001b[39m# cache not available\u001b[39;00m\n\u001b[0;32m---> <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=70'>71</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m io\u001b[39m.\u001b[39;49mimread(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfiles[index])\n\u001b[1;32m     <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=72'>73</a>\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__buffer_pos:\n\u001b[1;32m     <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=73'>74</a>\u001b[0m         \u001b[39m# reading the past...\u001b[39;00m\n\u001b[1;32m     <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=74'>75</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m io\u001b[39m.\u001b[39mimread(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles[index])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/skimage/io/_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/skimage/io/_io.py?line=49'>50</a>\u001b[0m         plugin \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtifffile\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/skimage/io/_io.py?line=51'>52</a>\u001b[0m \u001b[39mwith\u001b[39;00m file_or_url_context(fname) \u001b[39mas\u001b[39;00m fname:\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/skimage/io/_io.py?line=52'>53</a>\u001b[0m     img \u001b[39m=\u001b[39m call_plugin(\u001b[39m'\u001b[39;49m\u001b[39mimread\u001b[39;49m\u001b[39m'\u001b[39;49m, fname, plugin\u001b[39m=\u001b[39;49mplugin, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mplugin_args)\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/skimage/io/_io.py?line=54'>55</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(img, \u001b[39m'\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/skimage/io/_io.py?line=55'>56</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/skimage/io/manage_plugins.py:207\u001b[0m, in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/skimage/io/manage_plugins.py?line=202'>203</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/skimage/io/manage_plugins.py?line=203'>204</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCould not find the plugin \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/skimage/io/manage_plugins.py?line=204'>205</a>\u001b[0m                            (plugin, kind))\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/skimage/io/manage_plugins.py?line=206'>207</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/skimage/io/_plugins/imageio_plugin.py:10\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      <a href='file:///usr/local/lib/python3.8/dist-packages/skimage/io/_plugins/imageio_plugin.py?line=7'>8</a>\u001b[0m \u001b[39m@wraps\u001b[39m(imageio_imread)\n\u001b[1;32m      <a href='file:///usr/local/lib/python3.8/dist-packages/skimage/io/_plugins/imageio_plugin.py?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/skimage/io/_plugins/imageio_plugin.py?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(imageio_imread(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/imageio/__init__.py:86\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/__init__.py?line=64'>65</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(uri, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/__init__.py?line=65'>66</a>\u001b[0m     \u001b[39m\"\"\"imread(uri, format=None, **kwargs)\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/__init__.py?line=66'>67</a>\u001b[0m \n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/__init__.py?line=67'>68</a>\u001b[0m \u001b[39m    Reads an image from the specified file. Returns a numpy array, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/__init__.py?line=83'>84</a>\u001b[0m \u001b[39m        to see what arguments are available for a particular format.\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/__init__.py?line=84'>85</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/__init__.py?line=85'>86</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m imread_v2(uri, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/imageio/v2.py:160\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/v2.py?line=154'>155</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/v2.py?line=155'>156</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mInvalid keyword argument \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m \u001b[39m'\u001b[39m\u001b[39mperhaps you mean \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpilmode\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m?\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/v2.py?line=156'>157</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/v2.py?line=158'>159</a>\u001b[0m \u001b[39mwith\u001b[39;00m imopen(uri, \u001b[39m\"\u001b[39m\u001b[39mri\u001b[39m\u001b[39m\"\u001b[39m, plugin\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/v2.py?line=159'>160</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m file\u001b[39m.\u001b[39;49mread(index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py:133\u001b[0m, in \u001b[0;36mLegacyPlugin.read\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py?line=129'>130</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py?line=131'>132</a>\u001b[0m reader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlegacy_get_reader(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/core/legacy_plugin_wrapper.py?line=132'>133</a>\u001b[0m \u001b[39mreturn\u001b[39;00m reader\u001b[39m.\u001b[39;49mget_data(index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/imageio/core/format.py:404\u001b[0m, in \u001b[0;36mFormat.Reader.get_data\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/core/format.py?line=401'>402</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_BaseReaderWriter_last_index \u001b[39m=\u001b[39m index\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/core/format.py?line=402'>403</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/core/format.py?line=403'>404</a>\u001b[0m     im, meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data(index, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/core/format.py?line=404'>405</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/core/format.py?line=405'>406</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py:482\u001b[0m, in \u001b[0;36mJPEGFormat.Reader._get_data\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py?line=480'>481</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_data\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py?line=481'>482</a>\u001b[0m     im, info \u001b[39m=\u001b[39m PillowFormat\u001b[39m.\u001b[39;49mReader\u001b[39m.\u001b[39;49m_get_data(\u001b[39mself\u001b[39;49m, index)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py?line=483'>484</a>\u001b[0m     \u001b[39m# Handle exif\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py?line=484'>485</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mexif\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m info:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py:345\u001b[0m, in \u001b[0;36mPillowFormat.Reader._get_data\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py?line=342'>343</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_im\u001b[39m.\u001b[39mpalette\u001b[39m.\u001b[39mrawmode_saved \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_im\u001b[39m.\u001b[39mpalette\u001b[39m.\u001b[39mrawmode\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py?line=343'>344</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_im\u001b[39m.\u001b[39mgetdata()[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py?line=344'>345</a>\u001b[0m im \u001b[39m=\u001b[39m pil_get_frame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_im, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_kwargs)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py?line=345'>346</a>\u001b[0m \u001b[39mreturn\u001b[39;00m im, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_im\u001b[39m.\u001b[39minfo\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py:782\u001b[0m, in \u001b[0;36mpil_get_frame\u001b[0;34m(im, is_gray, as_gray, mode, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py?line=779'>780</a>\u001b[0m     \u001b[39mif\u001b[39;00m im\u001b[39m.\u001b[39mformat \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPNG\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m im\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py?line=780'>781</a>\u001b[0m         dtype \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muint16\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py?line=781'>782</a>\u001b[0m     frame \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(frame, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/imageio/plugins/pillow_legacy.py?line=783'>784</a>\u001b[0m \u001b[39mreturn\u001b[39;00m frame\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py:675\u001b[0m, in \u001b[0;36mImage.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=672'>673</a>\u001b[0m     new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtobytes(\u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=673'>674</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=674'>675</a>\u001b[0m     new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtobytes()\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=676'>677</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ArrayData(new), dtype)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py:735\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=731'>732</a>\u001b[0m \u001b[39mif\u001b[39;00m s \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=732'>733</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mencoder error \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m}\u001b[39;00m\u001b[39m in tobytes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=734'>735</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.load_layer_weights(0, \"resnet34.dat\")\n",
    "nn.freeze_layer(0)\n",
    "\n",
    "#nn.load_weights('eye_resnet18.dat')\n",
    "#nn.freeze_layer(0)\n",
    "nn.train_model(ds, batch_size=16, num_epochs=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model with the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 1% [4 / 6564 files]\n",
      "testing 2% [72 / 6564 files]\n",
      "testing 3% [140 / 6564 files]\n",
      "testing 4% [208 / 6564 files]\n",
      "testing 5% [276 / 6564 files]\n",
      "testing 6% [344 / 6564 files]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_disease_classification_resnet2.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f637269737469616e6f2f446f63756d656e74732f50726f6a656374732f4d6573747261646f2f566973616f436f6d7075746163696f6e616c/workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_disease_classification_resnet2.ipynb#ch0000007vscode-remote?line=0'>1</a>\u001b[0m nn\u001b[39m.\u001b[39;49mtest_model(ds)\n",
      "File \u001b[0;32m/workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_classifier.py:168\u001b[0m, in \u001b[0;36mEyeClassifier.test_model\u001b[0;34m(self, dataset, batch_size, gpu, verbose)\u001b[0m\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_classifier.py?line=164'>165</a>\u001b[0m num_files \u001b[39m=\u001b[39m testing_size \u001b[39m*\u001b[39m batch_size\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_classifier.py?line=165'>166</a>\u001b[0m num_processed_files \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_classifier.py?line=167'>168</a>\u001b[0m \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m test_loader:\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_classifier.py?line=169'>170</a>\u001b[0m     device \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__device\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/eye_classifier.py?line=170'>171</a>\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=518'>519</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=523'>524</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=524'>525</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=558'>559</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=559'>560</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=560'>561</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=561'>562</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py?line=562'>563</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py:109\u001b[0m, in \u001b[0;36mEyeImageDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=105'>106</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img)\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=107'>108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=108'>109</a>\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=110'>111</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///workspaces/VisaoComputacional/trabalho-final/src/deep-learning/../utils/eye_dataset.py?line=111'>112</a>\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py:61\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py?line=58'>59</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py?line=59'>60</a>\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py?line=60'>61</a>\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py:304\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py?line=295'>296</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py?line=296'>297</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py?line=297'>298</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py?line=298'>299</a>\u001b[0m \u001b[39m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py?line=301'>302</a>\u001b[0m \u001b[39m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py?line=302'>303</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py?line=303'>304</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mresize(img, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mantialias)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:419\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py?line=414'>415</a>\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py?line=415'>416</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py?line=416'>417</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py?line=417'>418</a>\u001b[0m     pil_interpolation \u001b[39m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py?line=418'>419</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F_pil\u001b[39m.\u001b[39;49mresize(img, size\u001b[39m=\u001b[39;49msize, interpolation\u001b[39m=\u001b[39;49mpil_interpolation, max_size\u001b[39m=\u001b[39;49mmax_size)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py?line=420'>421</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39mresize(img, size\u001b[39m=\u001b[39msize, interpolation\u001b[39m=\u001b[39minterpolation\u001b[39m.\u001b[39mvalue, max_size\u001b[39m=\u001b[39mmax_size, antialias\u001b[39m=\u001b[39mantialias)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_pil.py:258\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_pil.py?line=254'>255</a>\u001b[0m             new_short, new_long \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(max_size \u001b[39m*\u001b[39m new_short \u001b[39m/\u001b[39m new_long), max_size\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_pil.py?line=256'>257</a>\u001b[0m     new_w, new_h \u001b[39m=\u001b[39m (new_short, new_long) \u001b[39mif\u001b[39;00m w \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m h \u001b[39melse\u001b[39;00m (new_long, new_short)\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_pil.py?line=257'>258</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mresize((new_w, new_h), interpolation)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_pil.py?line=258'>259</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_pil.py?line=259'>260</a>\u001b[0m     \u001b[39mif\u001b[39;00m max_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py:1980\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=1971'>1972</a>\u001b[0m             \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mreduce(\u001b[39mself\u001b[39m, factor, box\u001b[39m=\u001b[39mreduce_box)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=1972'>1973</a>\u001b[0m         box \u001b[39m=\u001b[39m (\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=1973'>1974</a>\u001b[0m             (box[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m factor_x,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=1974'>1975</a>\u001b[0m             (box[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m factor_y,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=1975'>1976</a>\u001b[0m             (box[\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m factor_x,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=1976'>1977</a>\u001b[0m             (box[\u001b[39m3\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m factor_y,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=1977'>1978</a>\u001b[0m         )\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/PIL/Image.py?line=1979'>1980</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim\u001b[39m.\u001b[39;49mresize(size, resample, box))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "nn.test_model(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the network with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(nn.state_dict(), \"eye_resnet18.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "\n",
    "apply_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=input_size),\n",
    "    transforms.CenterCrop(size=input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "ds = EyeImageDataset(root=image_dir_testing, data_info_csv_file=csv_file, transform=apply_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.test_model(ds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
