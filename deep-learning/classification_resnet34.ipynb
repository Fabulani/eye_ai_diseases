{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.eye_dataset import *\n",
    "from eye_classifier import *\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Dataset\n",
    "\n",
    "We use the utility class EyeImageDataset() to load the training dataset based on the metadata CSV file and\n",
    "the target image folder\n",
    "\n",
    "The training images will be loaded as needed due to memory constraints.\n",
    "\n",
    "Since we're using RESNET-34 network as the convolutional layers, we need to resize our images to 224x224, so we apply\n",
    "some transforms on our dataset.\n",
    "\n",
    "We also need to proper normalize the dataset accordingly to the RESNET specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../../data\"\n",
    "image_dir = f\"{base_dir}/preprocessed_images\"\n",
    "\n",
    "image_dir_training = f\"{base_dir}/ODIR-5K/training\"\n",
    "image_dir_testing = f\"{base_dir}/ODIR-5K/testing\"\n",
    "csv_file = f'{base_dir}/ODIR-5K/data.csv'\n",
    "\n",
    "print ('reading input dataset')\n",
    "input_size = 224\n",
    "\n",
    "apply_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=input_size),\n",
    "    transforms.CenterCrop(size=input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "ds = EyeImageDataset(root=image_dir_training, data_info_csv_file=csv_file, transform=apply_transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "\n",
    "To build the model, we use the utility superclass EyeClassifier. \n",
    "\n",
    "We create a subclass named ResnetEyeClassifier and then we feed it with the intended model on its __init__ constructor.\n",
    "\n",
    "Here we're building a resnet34 as the first layer (in fact resnet18 is comprised of many layers), followed by three linear fully connected layers\n",
    "for image classification\n",
    "\n",
    "The last layer will not have a transfer function because we opted to use CrossEntropyLoss as the loss function. \n",
    "\n",
    "You can change the loss function by using set_loss_function() if you wish to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetEyeClassifier(EyeClassifier):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super(ResnetEyeClassifier, self).__init__(model=[\n",
    "\n",
    "            (models.resnet34(pretrained=False), TransferFunction.NotApplicable),\n",
    "\n",
    "            (nn.Linear(in_features=1000, out_features=256),\n",
    "             TransferFunction.LeakyRelu),\n",
    "\n",
    "            (nn.Linear(in_features=256, out_features=64),\n",
    "             TransferFunction.LeakyRelu),\n",
    "\n",
    "            (nn.Linear(in_features=64, out_features=16),\n",
    "             TransferFunction.Relu),\n",
    "\n",
    "            (nn.Linear(in_features=16, out_features=num_classes),\n",
    "             TransferFunction.NotApplicable),\n",
    "        ])\n",
    "\n",
    "\n",
    "nn = ResnetEyeClassifier(num_classes=len(ds.classes))\n",
    "print(nn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Training the model is very easy. All we have to do is to call train_model() passing the EyeImageDataset object. \n",
    "\n",
    "If you're having I/O constraints, you can use the set_buffer_size(n) method to cache n images in memory. Be aware that you cant use it\n",
    "along with shuffle, because the cache will be constantly invalidated, unless you have a lot of memory and cache all of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.train_model(ds, batch_size=16, num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "\n",
    "Testing the model is similar to training it. All we have to do is to call test_model() passing a EyeImageDataset object pointing to the test dataset images. \n",
    "\n",
    "If you're having I/O constraints, you can use the set_buffer_size(n) method to cache n images in memory. Be aware that you cant use it\n",
    "along with shuffle, because the cache will be constantly invalidated, unless you have a lot of memory and cache all of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "\n",
    "apply_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=input_size),\n",
    "    transforms.CenterCrop(size=input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "ds = EyeImageDataset(root=image_dir_testing, data_info_csv_file=csv_file, transform=apply_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.test_model(ds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
